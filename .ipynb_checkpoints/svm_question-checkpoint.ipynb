{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "import numpy as np\n",
    "from numpy import column_stack\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle \n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, RobustScaler\n",
    "\n",
    "# time\n",
    "import time\n",
    "\n",
    "# Ignore Warnings\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_csv(filepath_or_buffer=path ,\n",
    "                       sep=',',\n",
    "                       names=['age', 'workclass' , 'education', 'marital_status', 'occupation', 'Race', 'sex' ,'hpw', 'native_country', 'income_pa'])\n",
    "\n",
    "def preprocess_data():\n",
    "    \n",
    "    \"\"\"\n",
    "    returns one-hot-encoded for categorical and scaled for continuous features\n",
    "    \"\"\"\n",
    "    \n",
    "    col_one_hot_encode = train_X.select_dtypes(include=['object']).columns.tolist()\n",
    "    col_continuous = train_X.select_dtypes(include=['int64']).columns.tolist()\n",
    "    \n",
    "    train_col = []\n",
    "    test_col = []\n",
    "    dev_col = []\n",
    "    \n",
    "    \n",
    "    for col in train_X.columns.tolist():\n",
    "        \n",
    "        if col in col_one_hot_encode:\n",
    "            \n",
    "            \"\"\"\n",
    "            One-hot-encode categorical variables\n",
    "            \"\"\"\n",
    "            \n",
    "            # Label_encoder\n",
    "            # fit label encoder\n",
    "            label_encoder = LabelEncoder().fit(train_X[col])\n",
    "            # transform label encoder       \n",
    "            train_feature = label_encoder.transform(train_X[col])\n",
    "            test_feature = label_encoder.transform(test_X[col])\n",
    "            dev_feature = label_encoder.transform(dev_X[col])\n",
    "            \n",
    "            \n",
    "            # reshape features\n",
    "            train_feature = train_feature.reshape(train_X.shape[0], 1)\n",
    "            test_feature = test_feature.reshape(test_X.shape[0], 1)\n",
    "            dev_feature = dev_feature.reshape(dev_X.shape[0], 1)\n",
    "            \n",
    "            \n",
    "            # onehot encoder\n",
    "            # fit_onehot_encoder\n",
    "            onehot_encoder = OneHotEncoder(sparse=False).fit(train_feature)\n",
    "            # transform_one_hot_encoder\n",
    "            train_feature = onehot_encoder.transform(train_feature)\n",
    "            test_feature = onehot_encoder.transform(test_feature)\n",
    "            dev_feature = onehot_encoder.transform(dev_feature)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if col in col_continuous:\n",
    "            \n",
    "            \"\"\"\n",
    "            Standardize continuous variables\n",
    "            \"\"\"\n",
    "            \n",
    "            # Minmax scaler\n",
    "            # fit scaler\n",
    "            m_scaler = RobustScaler().fit(np.array(train_X[col]).reshape(-1,1))\n",
    "            # transform using scaler\n",
    "            train_feature = m_scaler.transform(np.array(train_X[col]).reshape(-1,1))\n",
    "            test_feature = m_scaler.transform(np.array(test_X[col]).reshape(-1,1))\n",
    "            dev_feature = m_scaler.transform(np.array(dev_X[col]).reshape(-1,1))\n",
    "            \n",
    "            \n",
    "        # append\n",
    "        train_col.append(np.array(train_feature))\n",
    "        test_col.append(np.array(test_feature))\n",
    "        dev_col.append(np.array(dev_feature))\n",
    "        \n",
    "        \n",
    "    return column_stack(train_col), column_stack(test_col), column_stack(dev_col)\n",
    "\n",
    "\n",
    "def split_features_y(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns input features and output feature\n",
    "    \"\"\"\n",
    "    \n",
    "    label_en = LabelEncoder().fit(train_df['income_pa'])\n",
    "    \n",
    "    return df.iloc[:,:-1], np.where( label_en.transform(df['income_pa']) == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training data\n",
      "Load testing data\n",
      "Load dev set\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "print('Load training data')\n",
    "train_df = load_data(path='income-data/income.train.txt')\n",
    "\n",
    "# load testing data\n",
    "print('Load testing data')\n",
    "test_df = load_data(path='income-data/income.test.txt')\n",
    "\n",
    "#load dev data\n",
    "print('Load dev set')\n",
    "dev_df = load_data(path='income-data/income.dev.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data consists of 25000 rows and 94 columns \n",
      "Testing data consists of 2145 rows and 94 columns \n",
      "Development data consists of 1508 rows and 94 columns \n"
     ]
    }
   ],
   "source": [
    "# split input_features and output_feature\n",
    "train_X , Y_train = split_features_y(train_df)\n",
    "test_X, Y_test = split_features_y(test_df)\n",
    "dev_X, Y_dev = split_features_y(dev_df)\n",
    "\n",
    "# Preprocess Data\n",
    "X_train , X_test, X_dev = preprocess_data()\n",
    "\n",
    "\n",
    "print('Training data consists of %s rows and %s columns ' % (X_train.shape[0], X_train.shape[1]) )\n",
    "print('Testing data consists of %s rows and %s columns ' % (X_test.shape[0], X_test.shape[1]) )\n",
    "print('Development data consists of %s rows and %s columns ' % (X_dev.shape[0], X_dev.shape[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_a():\n",
    "    \n",
    "    C = [0.0001, 0.001, 0.01, 0.1, 1 , 10, 100, 1000, 10000]\n",
    "    \n",
    "    train_acc ={}\n",
    "    test_acc = {}\n",
    "    dev_acc = {}\n",
    "    train_acc_n_vec = {}\n",
    "    \n",
    "    for c in C:\n",
    "        print('Evaluating Model for : ', c)\n",
    "        model = SVC(C=c, kernel='linear', verbose=True)\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        train_acc[c] = model.score(X_train, Y_train)\n",
    "        train_acc_n_vec[c] = model\n",
    "        test_acc[c] = model.score(X_test, Y_test)\n",
    "        dev_acc[c] = model.score(X_dev, Y_dev)\n",
    "        \n",
    "    return train_acc, test_acc, dev_acc, train_acc_n_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model for :  0.0001\n",
      "[LibSVM]Evaluating Model for :  0.001\n",
      "[LibSVM]Evaluating Model for :  0.01\n",
      "[LibSVM]Evaluating Model for :  0.1\n",
      "[LibSVM]Evaluating Model for :  1\n",
      "[LibSVM]Evaluating Model for :  10\n",
      "[LibSVM]Evaluating Model for :  100\n",
      "[LibSVM]Evaluating Model for :  1000\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_acc_svma, test_acc_svma, dev_acc_svma, train_num_vec = svm_a( )\n",
    "print('Time taken : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svma(titl):\n",
    "    \n",
    "    x_train_svma, y_train_svma = zip(*sorted(train_acc_svma.items()))\n",
    "    x_test_svma, y_test_svma = zip(*sorted(test_acc_svma.items()))\n",
    "    x_dev_svma, y_dev_svma = zip(*sorted(dev_acc_svma.items()))\n",
    "    \n",
    "    x = [1, 2, 3, 4, 5, 6 ,7, 8, 9]\n",
    "    y_tr = [y * 100 for y in y_train_svma]\n",
    "    y_tst = [y * 100 for y in y_test_svma]\n",
    "    y_dev = [y * 100 for y in y_dev_svma]\n",
    "    \n",
    "    labels = ['0.0001', '0.001', '0.01', '0.1', '1', '10', '100', '1000', '10000']\n",
    "    \n",
    "    plt.plot(x, y_tr, 'ro', color='b', label='train' , linestyle='-')\n",
    "    plt.plot(x, y_tst, 'ro', color='g', label ='test' , linestyle='-')\n",
    "    plt.plot(x, y_dev, 'ro', color='y', label = 'dev' , linestyle='-')\n",
    "    \n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.margins(0.2)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Values of C')\n",
    "    plt.title(titl)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(titl+'.jpg', dpi=300)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svma('Training, Testing and Dev Set accuracy as function of C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_val =[]\n",
    "num_c_val = []\n",
    "for k,v in train_num_vec.items():\n",
    "    c_val.append(k)\n",
    "    num_c_val.append(len(v.support_))\n",
    "    \n",
    "x = [1, 2, 3, 4, 5, 6 ,7, 8, 9]\n",
    "labels = c_val\n",
    "\n",
    "plt.plot(x, num_c_val, 'ro', color='b', label='Number of support vector' , linestyle='-')\n",
    "plt.xticks(x, labels, rotation='vertical')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Values of C')\n",
    "plt.ylabel('Number of support vector')\n",
    "plt.title('Number of support vectors as a function of c')\n",
    "plt.savefig('Number of support vectors as a function of c.jpg', dpi=300)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_b(x_train, y_train, x_tst, y_tst):\n",
    "    \n",
    "    model = SVC(kernel='linear', C=10000)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    results = model.predict(x_tst)\n",
    "    \n",
    "    print(confusion_matrix(y_tst, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation set\n",
    "comb_X_data =  np.concatenate((X_train, X_dev), axis=0)\n",
    "comb_Y_data = np.concatenate((Y_train, Y_dev), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_b(comb_X_data, comb_Y_data, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_c(k_type, i):\n",
    "    \n",
    "    model = SVC(kernel=k_type, C=10000, degree=i)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_linear = svm_c(k_type='linear', i=2)\n",
    "model_2_poly = svm_c(k_type='poly', i=2)\n",
    "model_3_poly = svm_c(k_type='poly', i=3)\n",
    "model_4_poly = svm_c(k_type='poly', i=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svm_c = {}\n",
    "\n",
    "# training_set\n",
    "train_svm_c['linear_2'] = model_2_linear.score(X_train, Y_train)\n",
    "train_svm_c['poly_2'] = model_2_poly.score(X_train, Y_train)\n",
    "train_svm_c['poly_3'] = model_3_poly.score(X_train, Y_train)\n",
    "train_svm_c['poly_4'] = model_4_poly.score(X_train, Y_train)\n",
    "\n",
    "test_svm_c = {}\n",
    "# testing_set\n",
    "test_svm_c['linear_2'] = model_2_linear.score(X_test, Y_test)\n",
    "test_svm_c['poly_2'] = model_2_poly.score(X_test, Y_test)\n",
    "test_svm_c['poly_3'] = model_3_poly.score(X_test, Y_test)\n",
    "test_svm_c['poly_4'] = model_4_poly.score(X_test, Y_test)\n",
    "\n",
    "dev_svm_c = {}\n",
    "# dev_set\n",
    "dev_svm_c['linear_2'] = model_2_linear.score(X_dev, Y_dev)\n",
    "dev_svm_c['poly_2'] = model_2_poly.score(X_dev, Y_dev)\n",
    "dev_svm_c['poly_3'] = model_3_poly.score(X_dev, Y_dev)\n",
    "dev_svm_c['poly_4'] = model_4_poly.score(X_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_c(titl):\n",
    "    \n",
    "    x_train_svmc, y_train_svmc = zip(*sorted(train_svm_c.items()))\n",
    "    x_test_svmc, y_test_svmc = zip(*sorted(test_svm_c.items()))\n",
    "    x_dev_svmc, y_dev_svmc = zip(*sorted(dev_svm_c.items()))\n",
    "    \n",
    "    x = [1, 2, 3, 4]\n",
    "    y_tr = [y * 100 for y in y_train_svmc]\n",
    "    y_tst = [y * 100 for y in y_test_svmc]\n",
    "    y_dev = [y * 100 for y in y_dev_svmc]\n",
    "    \n",
    "    labels = x_train_svmc\n",
    "    \n",
    "    plt.plot(x, y_tr, 'ro', color='b', label='train' , linestyle='-')\n",
    "    plt.plot(x, y_tst, 'ro', color='g', label ='test' , linestyle='-')\n",
    "    plt.plot(x, y_dev, 'ro', color='y', label = 'dev' , linestyle='-')\n",
    "    \n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.margins(0.2)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Kernel Settings')\n",
    "    plt.title(titl)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(titl+'.jpg', dpi=300)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm_c('Accuracy of train, test and dev with diff. kernel settings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    return +1 if num>0 else -1\n",
    "\n",
    "def r_y_kernel(row, aph, df_arr):\n",
    "    \n",
    "    ind_o = np.where(aph != 0)\n",
    "    score = 0\n",
    "    \n",
    "    for t_i, ind in zip(aph[ind_o], ind_o):\n",
    "        x_i = df_arr[int(ind[0])]\n",
    "        \n",
    "        score += np.sum(t_i * ((1 + np.dot(row, x_i)) ** 3))\n",
    "        \n",
    "    return -1 if score < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernalized_perceptron(deg, epochs):\n",
    "    \n",
    "    alpha = np.zeros(shape=(X_train.shape[0])) \n",
    "    count_mistakes_epochs = {}\n",
    "    \n",
    "    train_pred = []\n",
    "    test_pred = []\n",
    "    dev_pred = []\n",
    "    \n",
    "    \n",
    "    # compute gram matrix\n",
    "    print('Computing gram matrix')\n",
    "    gm = polynomial_kernel(X_train, degree=deg)\n",
    "    print('Gram matrix computed')\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        count_mistakes_batch = 0\n",
    "        \n",
    "        for j in range(X_train.shape[0]):\n",
    "            \n",
    "            y_pred = np.sign(np.sum(np.dot(gm[:,j], alpha)))\n",
    "            \n",
    "            if y_pred == 0:\n",
    "                y_pred = -1\n",
    "            \n",
    "            if y_pred != Y_train[j]:\n",
    "                \n",
    "                count_mistakes_batch +=1\n",
    "                \n",
    "                alpha[j] += Y_train[j]\n",
    "                \n",
    "        count_mistakes_epochs[i+1] = count_mistakes_batch\n",
    "        \n",
    "    for tr in range(len(X_train)):\n",
    "            train_pred.append(np.sign(r_y_kernel(X_train[tr], alpha, X_train)))\n",
    "            \n",
    "    train_acc = accuracy_score(Y_train, np.array(train_pred))\n",
    "            \n",
    "    for tr in range(len(X_test)):\n",
    "            test_pred.append(np.sign(r_y_kernel(X_test[tr], alpha, X_test)))\n",
    "    \n",
    "    test_acc = accuracy_score(Y_test, np.array(test_pred))\n",
    "            \n",
    "    for tr in range(len(X_dev)):\n",
    "            dev_pred.append(np.sign(r_y_kernel(X_dev[tr], alpha, X_dev)))\n",
    "            \n",
    "    dev_acc = accuracy_score(Y_dev, np.array(dev_pred))\n",
    "  \n",
    "    return count_mistakes_epochs, train_acc, test_acc, dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_erros, kp_train_acc, kp_test_acc, kp_dev_acc = kernalized_perceptron(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kp_mistakes(num_mis):\n",
    "    \n",
    "    # get results of standard perceptron\n",
    "    x,  y = zip(*sorted(num_mis.items()))\n",
    "    \n",
    "    \n",
    "    plt.plot(x, y, label='Number of Mistakes', marker='o')\n",
    "    plt.xticks(np.linspace(1,5 , 5))\n",
    "    plt.xlabel('Number Of Epochs')\n",
    "    plt.ylabel('Number of mistakes')\n",
    "    plt.legend(loc='upper middle')\n",
    "    plt.title('Number of mistakes per epoch in kernalized perceptron ')\n",
    "    plt.savefig('num_mistakes_sp_vs_avp.jpg', dpi=300)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kp_mistakes(kp_erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KP Accuracy on traning data %.2f ' %(kp_train_acc*100))\n",
    "print('KP Accuracy on testing data %.2f ' %(kp_test_acc*100))\n",
    "print('KP Accuracy on dev data %.2f ' %(kp_dev_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
